{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import *\n",
    "from utils import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem = problems.Quadratic(d=1, n=1024, seed=0)\n",
    "# show_problem(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 1)\n",
    "# for sample in val_offline_dataset:\n",
    "#     show_problem(sample['problem'], color='grey', ax=axes, x_min=False)\n",
    "#     plt.scatter(sample['problem'].info[\"x_min\"], sample['problem'].info[\"y_min\"], s=10, c='red', zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def run(model, sample):\n",
    "    if \"x\" in sample and \"y\" in sample:\n",
    "        outputs = model.model(\n",
    "            x=sample[\"x\"].unsqueeze(0).to(device),\n",
    "            y=sample[\"y\"].unsqueeze(0).to(device),\n",
    "        ).squeeze(0).detach().cpu()\n",
    "        return {\n",
    "            \"logits\": outputs,\n",
    "            \"predictions\": model.get_predictions(outputs),\n",
    "            \"targets\": sample[\"x_min\"]\n",
    "        }\n",
    "    \n",
    "        x = sample[\"x\"].cpu()\n",
    "        y = sample[\"y\"].cpu()\n",
    "    else:\n",
    "        outputs = model.run(\n",
    "            problem=sample[\"problem\"],\n",
    "            n_steps=model.config[\"model_params\"][\"seq_len\"]+1\n",
    "        )\n",
    "        logits = results['logits'].detach().cpu()\n",
    "        x = results[\"x\"].cpu()\n",
    "        y = results[\"y\"].cpu()\n",
    "    # probs = F.softmax(logits, -1)\n",
    "    probs = torch.round(logits[..., 0] * 1023)\n",
    "    return {\"logits\": logits, \"probs\": probs, \"x\": x, \"y\": y, \"target\": sample[\"x_min\"], \"problem\": sample[\"problem\"]}\n",
    "\n",
    "def show(results, title=\"\"):\n",
    "    probs = results[\"probs\"]\n",
    "\n",
    "    cmap = cm.get_cmap('jet')\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 4), gridspec_kw=dict(wspace=0.125))\n",
    "    plt.suptitle(title)\n",
    "    axes[1].set_title(\"Predicted Distribution\")\n",
    "    show_problem(results[\"problem\"], ax=axes[0], color=\"grey\", linestyle='--')\n",
    "\n",
    "    if probs.ndim == 2:\n",
    "        indexes = range(len(probs)) #np.linspace(0, len(probs)-1, 10+1, dtype=np.int32)\n",
    "        colors = [cmap(c) for c in np.linspace(0, 1, len(probs))]\n",
    "        # indexes = range(len(probs))\n",
    "        # colors = [cmap(c) for c in np.linspace(0, 1, len(indexes))]\n",
    "        for i in indexes:\n",
    "            axes[0].scatter(results[\"x\"][:i], results[\"y\"][:i], c=colors[1:i+1], zorder=2)\n",
    "            # axes[1].plot(results[\"probs\"][i], c=colors[i], label=i)\n",
    "    else:\n",
    "        color = cmap(1.0)\n",
    "        colors = [cmap(c) for c in np.linspace(0, 1, len(probs))]\n",
    "        print(results[\"x\"].shape, probs.shape)\n",
    "        if len(results[\"x\"]) == len(probs):\n",
    "            axes[0].scatter(results[\"x\"][:-1], results[\"y\"][:-1], color=colors[1:], zorder=2)\n",
    "        else:\n",
    "            axes[0].scatter(results[\"x\"], results[\"y\"], color=colors[1:], zorder=2)\n",
    "        for i in range(len(probs)):\n",
    "            axes[1].vlines(results[\"probs\"][i], 0, 1, colors=colors[i], zorder=2)\n",
    "        # axes[1].plot(results[\"probs\"], c=color, label=len(results[\"x\"]))\n",
    "\n",
    "    ymin, ymax = axes[1].get_ylim()\n",
    "    axes[1].vlines(x=results[\"target\"], ymin=0, ymax=ymax, colors='white', label='target')\n",
    "    axes[1].set_xlabel('x')\n",
    "\n",
    "    # axes[1].legend(loc=4)\n",
    "    axes[1].legend(loc='center left', title='# observations', bbox_to_anchor=(1, 0.55))\n",
    "\n",
    "    # plt.savefig(f'{title}.png')\n",
    "    plt.show()\n",
    "\n",
    "def runnshow(model, train_idx=0, val_idx=0):\n",
    "    model.train()\n",
    "    with torch.no_grad():\n",
    "        train_batch_train_mode = run(model, train_offline_dataset[train_idx])\n",
    "        valof_batch_train_mode = run(model, val_offline_dataset[val_idx])\n",
    "        show(train_batch_train_mode, title=\"Train problem: Offlain Training\")\n",
    "        show(valof_batch_train_mode, title=\"Validation problem: Offlain Training\")\n",
    "\n",
    "    model.eval()\n",
    "    # train_batch_eval_mode = run(model, train_offline_dataset[idx])\n",
    "    # valof_batch_eval_mode = run(model, val_offline_dataset[idx])\n",
    "    valon_batch_eval_mode = run(model, val_online_dataset[val_idx])\n",
    "    # show(train_batch_eval_mode, title=\"Train problem: Offlain Inference\")\n",
    "    # show(valof_batch_eval_mode, title=\"Validation problem: Offlain Inference\")\n",
    "    show(valon_batch_eval_mode, title=\"Validation problem: Onlain Inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_best_checkpoint(log_dir, key='epoch') -> str:\n",
    "    checkpoints = defaultdict(dict)\n",
    "    checkpoints_dir = os.path.join(log_dir, 'checkpoints')\n",
    "\n",
    "    pattern = r'epoch=(\\d+)-step=(\\d+)'\n",
    "\n",
    "    for filename in [file for file in os.listdir(checkpoints_dir)\n",
    "                 if file.endswith('.ckpt') and file != 'last.ckpt']:\n",
    "\n",
    "        epoch, step = re.findall(pattern, filename)[0]\n",
    "        checkpoints[filename] = {'epoch': epoch, 'step': step}  # Create a dictionary for the checkpoint\n",
    "\n",
    "    # Find the checkpoint with the maximum value for the given key\n",
    "    cpkt = max(checkpoints.keys(), key=lambda cp: float(checkpoints[cp][key]))\n",
    "    return os.path.join(checkpoints_dir, cpkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_file = '../results/DPT/gdbzctgp/checkpoints/epoch=499-step=1000.ckpt'\n",
    "run_name = \"cdv3c4id\"\n",
    "root_dir = os.path.join(\"..\", \"results\", \"DPT_2\", run_name)\n",
    "checkpoint_file = get_best_checkpoint(root_dir, 'epoch')\n",
    "\n",
    "model = DPTSolver.load_from_checkpoint(checkpoint_file).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"config.yaml\")\n",
    "config = model.config\n",
    "\n",
    "dl = get_dataloaders(config)\n",
    "\n",
    "train_offline_dataset = dl[\"train_dataloaders\"].dataset\n",
    "val_offline_dataset = dl[\"val_dataloaders\"][0].dataset\n",
    "val_online_dataset = dl[\"val_dataloaders\"][1].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_offline_dataset[0]\n",
    "outputs = model.model(\n",
    "    x=sample[\"x\"].unsqueeze(0).to(device),\n",
    "    y=sample[\"y\"].unsqueeze(0).to(device),\n",
    ").squeeze(0).detach().cpu()\n",
    "F.sigmoid(outputs[-1][0]), sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.scatter(sample[\"x\"], sample[\"y\"])\n",
    "# show_problem(sample[\"problem\"], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = train_offline_dataset[501]\n",
    "\n",
    "# fig = plt.figure(figsize=(6, 3))\n",
    "# ax = plt.gca()\n",
    "# show_problem(sample[\"problem\"], ax=ax, color=\"grey\", linestyle='--')\n",
    "# cmap = cm.get_cmap('jet')\n",
    "# colors = [cmap(c) for c in np.linspace(0, 1, config[\"model_params\"][\"seq_len\"])]\n",
    "# ax.scatter(sample[\"x\"], sample[\"y\"], c=colors, zorder=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(3, 8))\n",
    "# ax = plt.gca()\n",
    "# for i in range(10):\n",
    "#     sample = val_offline_dataset[i]\n",
    "#     show_problem(sample[\"problem\"], ax=ax, color=\"grey\", linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_targets = torch.tensor([sample[\"x_min\"] for sample in train_offline_dataset])\n",
    "# val_targets = torch.tensor([sample[\"x_min\"] for sample in val_offline_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnshow(model, train_idx=100, val_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "valon_batch_eval_mode = run(model, val_online_dataset[2])\n",
    "show(valon_batch_eval_mode, title=\"Validation problem: Online Inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# targets = torch.tensor([val_online_dataset[i][\"x_min\"] for i in range(len(val_online_dataset))])\n",
    "# sort_indexes = torch.argsort(targets)\n",
    "\n",
    "# for idx in sort_indexes:\n",
    "#     results = run(model, val_online_dataset[idx])\n",
    "#     show(results, title=f'train/{idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_offline_dataset\n",
    "# dataset = val_offline_dataset\n",
    "model.train()\n",
    "\n",
    "# dataset = val_online_dataset\n",
    "# model.eval()\n",
    "\n",
    "targets = torch.tensor([dataset[i][\"x_min\"] for i in range(len(dataset))])\n",
    "sort_indexes = torch.argsort(targets)[::100]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4), gridspec_kw=dict(wspace=0.125), sharey=True)\n",
    "axes[0].set_title('Zero step')\n",
    "axes[1].set_title('First step')\n",
    "axes[2].set_title('Last step')\n",
    "\n",
    "cmap = cm.get_cmap('jet')\n",
    "colors = [cmap(c) for c in np.linspace(0, 1, len(sort_indexes))]\n",
    "for i, c in zip(sort_indexes, colors):\n",
    "    results = run(model, dataset[i])\n",
    "    target = results['target'].item()\n",
    "    axes[0].plot(results['probs'][0], c=c, label=target)\n",
    "    axes[1].plot(results['probs'][1], c=c, label=target)\n",
    "    # axes[2].plot(results['probs'][-1], c=c, label=target)\n",
    "axes[0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpt.train import Loss\n",
    "\n",
    "loss = Loss(\n",
    "    num_classes=config[\"model_params\"][\"num_actions\"],\n",
    "    seq_len=config[\"model_params\"][\"seq_len\"]+1,\n",
    "    eps=config[\"label_smoothing\"],\n",
    "    mode=config[\"loss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runnshow2(results, loss, u):\n",
    "    # show loss\n",
    "    plt.figure(figsize=(16, 3))\n",
    "    plt.title('Loss')\n",
    "    plt.plot(loss)\n",
    "    plt.xlabel('Number of ')\n",
    "    plt.show()\n",
    "\n",
    "    # compare distributions 1\n",
    "    n = 5 #len(u)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(16, 3), gridspec_kw=dict(wspace=0.05))\n",
    "    for i in range(n):\n",
    "        axes[i].set_title(f'{i} observations')\n",
    "        axes[i].plot(results[\"probs\"][i], c='red', label='predicted')\n",
    "        axes[i].plot(u[i], c='blue', label='ground truth')\n",
    "\n",
    "    axes[0].legend()\n",
    "    plt.show()\n",
    "\n",
    "    # # compare distributions 2\n",
    "    # cmap = cm.get_cmap('jet')\n",
    "    # colors = [cmap(c) for c in np.linspace(0, 1, len(u))]\n",
    "    # _, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
    "    # step = 10\n",
    "    # for i in np.linspace(0, len(u)-1, step+1, dtype=np.int32):\n",
    "    #     axes[0].plot(results[\"probs\"][i], c=colors[i])\n",
    "    #     axes[1].plot(u[i], c=colors[i], label=i)\n",
    "    # axes[1].legend(prop={'size': 8})\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "results = run(model, train_offline_dataset[1])\n",
    "# results = run(model, val_offline_dataset[1])\n",
    "\n",
    "predictions = results[\"logits\"].unsqueeze(0).to(device)\n",
    "targets = results[\"target\"].unsqueeze(0).repeat(1, config[\"model_params\"][\"seq_len\"]+1).to(device)\n",
    "l = loss(predictions, targets, reduction='none').squeeze(0).cpu()\n",
    "u = loss.u.squeeze(0).cpu().T\n",
    "\n",
    "runnshow2(results, l, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "def gif(results, title='result'):\n",
    "    probs = results[\"probs\"]\n",
    "\n",
    "    cmap = cm.get_cmap('jet')\n",
    "    colors = [cmap(c) for c in np.linspace(0, 1, len(probs))]\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(5, 5), sharex=True, gridspec_kw=dict(hspace=0))\n",
    "\n",
    "    def init():\n",
    "        problem = results[\"problem\"]\n",
    "        i = get_xaxis(problem.d, problem.n)\n",
    "        y = problem.target(i)\n",
    "        axes[0].set_title(\"Target Function\")\n",
    "        axes[0].plot(y, '--', c='grey', markersize=1)\n",
    "        ymin, ymax = axes[0].get_ylim()\n",
    "        axes[0].vlines(x=results[\"target\"], ymin=ymin, ymax=y.min(), colors='white')\n",
    "        axes[0].set_ylim(ymin, ymax)\n",
    "\n",
    "    def update(i):\n",
    "        # axes[0].clear()\n",
    "        axes[1].clear()\n",
    "        axes[0].scatter(results[\"x\"][:i], results[\"y\"][:i], c=colors[:i], zorder=2)\n",
    "        axes[1].plot(results[\"probs\"][i], c=colors[i], label=i)\n",
    "\n",
    "        ymin, ymax = axes[1].get_ylim()\n",
    "        axes[1].vlines(x=results[\"target\"], ymin=0, ymax=ymax, colors='white')\n",
    "        axes[1].vlines(x=results[\"x\"][i], ymin=0, ymax=ymax, colors='white')\n",
    "\n",
    "    frames = np.linspace(0, len(probs)-1, 10+1, dtype=np.int32)\n",
    "    frames = range(len(probs))\n",
    "    ani = FuncAnimation(fig, update, init_func=init, frames=frames)\n",
    "    ani.save(f'{title}.gif', writer=PillowWriter(fps=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "results = run(model, val_online_dataset[10])\n",
    "gif(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
