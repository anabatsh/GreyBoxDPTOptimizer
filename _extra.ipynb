{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpt_run import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solvers.dpt.utils.data import MarkovianOfflineDataset, load_markovian_learning_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = MarkovianOfflineDataset(\"../GreyBoxDPTOptimizerData/trajectories/Net_d_2_n_4_solvers\")\n",
    "dataset = MarkovianOfflineDataset(\"../GreyBoxDPTOptimizerData/trajectories/Quadratic_d_1_n_1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]['actions'], dataset[0]['target_action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = []\n",
    "\n",
    "# for epoch in range(100):\n",
    "for i, sample in enumerate(dataset):\n",
    "    track.append(sum(sample['actions'] == sample['target_action']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_problem(problems.Quadratic(d=1, n=1024, seed=np.random.randint(0, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('dpt_run_config.yaml')\n",
    "dataloaders = get_dataloaders(config)\n",
    "\n",
    "train_offline_batch = next(iter(dataloaders['train_dataloaders']))\n",
    "for key, val in train_offline_batch.items():\n",
    "    print(f'{key:>13} {list(val.shape)}')\n",
    "print()\n",
    "\n",
    "val_offline_batch = next(iter(dataloaders['val_dataloaders'][0]))\n",
    "for key, val in val_offline_batch.items():\n",
    "    print(f'{key:>13} {list(val.shape)}')\n",
    "\n",
    "# print()\n",
    "# val_online_batch = next(iter(dataloaders['val_dataloaders'][1]))\n",
    "# for key, val in val_online_batch[0].items():\n",
    "#     try:\n",
    "#         print(f'{key:>13} {list(val.shape)}')\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DPTSolver(config)\n",
    "model._offline_step(train_offline_batch, 0)\n",
    "\n",
    "model.eval()\n",
    "model._offline_step(val_offline_batch, 0)\n",
    "# model._online_step(val_online_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python dpt_run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPT Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "\n",
    "from solvers.dpt.train import DPTSolver\n",
    "from problems import Net\n",
    "from dpt_run import get_online_dataloader, load_config\n",
    "from utils import print_trajectory\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from problems import Net\n",
    "# from utils import *\n",
    "\n",
    "# problem = Net(d=4, n=2, seed=0)\n",
    "# all_actions = get_xaxis(d=problem.d, n=problem.n)\n",
    "# all_states = problem.target(all_actions)\n",
    "# print(np.array([all_states.max()]).shape)\n",
    "# print(np.empty(shape=(1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = torch.randn(size=(1, 10))\n",
    "# # plt.plot(logits[0])\n",
    "\n",
    "# for t in (0.01, 0.5, 1.0, 1.5, 2.0, 5.0, 100.0):\n",
    "#     probs_t = torch.nn.functional.softmax(logits / t, dim=-1)\n",
    "#     plt.plot(probs_t[0], label=t)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('config.yaml')\n",
    "\n",
    "d = int(np.log2(config[\"model_params\"][\"num_actions\"]))\n",
    "problems = [Net(d=d, n=2, seed=i) for i in range(271, 281)]\n",
    "val_online_dataloader = get_online_dataloader(problems, config)\n",
    "print('val_online_dataloader:', len(val_online_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = '../GreyBoxDPTOptimizerData/GreyBoxDPTOptimizer/0cxrd4bf/checkpoints/epoch=299-step=9600.ckpt'\n",
    "model = DPTSolver.load_from_checkpoint(checkpoint_file).to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_temperature(temperature_function):\n",
    "    visited_points = []\n",
    "    convergency_step = []\n",
    "\n",
    "    for _ in range(10):\n",
    "        for batch in val_online_dataloader:\n",
    "            for sample in batch:\n",
    "                result = model.run(\n",
    "                    **sample,\n",
    "                    n_steps=config[\"model_params\"][\"seq_len\"],\n",
    "                    return_trajectory=True,\n",
    "                    temperature_function=temperature_function\n",
    "                )\n",
    "                right_action_indexes = torch.where(result[\"actions\"] == sample[\"target_action\"])[0]\n",
    "                if len(right_action_indexes):\n",
    "                    right_action_step = right_action_indexes[0].item() + 1\n",
    "                    visited_points_number = len(torch.unique(result[\"actions\"][:right_action_step]))\n",
    "                else:\n",
    "                    right_action_step = np.nan\n",
    "                    visited_points_number = np.nan\n",
    "                convergency_step.append(right_action_step)\n",
    "                visited_points.append(visited_points_number)\n",
    "            # print(model._online_step(batch, 0))\n",
    "            # break\n",
    "    mask = np.isnan(convergency_step)\n",
    "    if mask.all():\n",
    "        convergency_step = np.nan\n",
    "        visited_points = np.nan\n",
    "    else:\n",
    "        convergency_step = np.nanmean(convergency_step)\n",
    "        visited_points = np.nanmean(visited_points)\n",
    "    return convergency_step, visited_points, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_results = {}\n",
    "temperature_functions = {\n",
    "   'argmax': lambda x: 0,\n",
    "    't = 0.00001': lambda x: 0.00001,\n",
    "    't = 0.5': lambda x: 0.5,\n",
    "    't = 1.0': lambda x: 1.0, \n",
    "    't = 10':  lambda x: 10,\n",
    "    't = 100': lambda x: 100,\n",
    "    't ~ 1 - n_step / n_steps': lambda x: 1 - x / config[\"model_params\"][\"seq_len\"],\n",
    "    't ~ 10 * (1 - n_step / n_steps)': lambda x: 10 * (1 - x / config[\"model_params\"][\"seq_len\"]),\n",
    "    't ~ 100 * (1 - n_step / n_steps)': lambda x: 100 * (1 - x / config[\"model_params\"][\"seq_len\"]) \n",
    "}\n",
    "for name, temperature_function in temperature_functions.items():\n",
    "   convergency_step, visited_points, mask = check_temperature(temperature_function)\n",
    "   temperature_results[name] = dict(\n",
    "      convergency_step=convergency_step, \n",
    "      visited_points=visited_points, \n",
    "      mask=mask,\n",
    "      temperature_function=temperature_function\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = config[\"model_params\"][\"seq_len\"]\n",
    "n_step_range = np.arange(0, seq_len)\n",
    "num_actions = config[\"model_params\"][\"num_actions\"]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for name, result in temperature_results.items():\n",
    "    print(f'Temperature function: {name}')\n",
    "    if result['mask'].all():\n",
    "        print('Has not converged')\n",
    "    else:\n",
    "        s_1 = f'Converged at {result[\"convergency_step\"]:.1f}/{seq_len} step'\n",
    "        s_2 = f' in {np.sum(~result[\"mask\"])}/{len(result[\"mask\"])} cases'\n",
    "        s_3 = f' and visited {result[\"visited_points\"]:.1f}/{num_actions} points'\n",
    "        print(s_1 + s_2 + s_3)\n",
    "    print()\n",
    "    plt.plot(n_step_range, [result[\"temperature_function\"](n_step) for n_step in n_step_range], label=name)\n",
    "\n",
    "plt.hlines(0, n_step_range[0], n_step_range[-1])\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_trajectory(result, problems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = L.Trainer(\n",
    "#     precision=config[\"precision\"],\n",
    "#     enable_model_summary=False\n",
    "# )\n",
    "# trainer.test(model, dataloaders=val_online_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(checkpoint_file)\n",
    "# print(checkpoint['hyper_parameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DPT Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "\n",
    "from solvers.dpt.train import DPTSolver\n",
    "from dpt_run_2 import *\n",
    "# from dpt_run import *\n",
    "\n",
    "from problems import Quadratic, Net\n",
    "from utils import print_trajectory\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dpt_run_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from dpt_run_2 import *\n",
    "\n",
    "config = load_config('config.yaml')\n",
    "\n",
    "train_offline_dataloader = get_offline_dataloader(config[\"train_histories_path\"], config)\n",
    "val_offline_dataloader = get_offline_dataloader(config[\"val_histories_path\"], config)\n",
    "print('train_offline_dataloader:', len(train_offline_dataloader.dataset))\n",
    "print('val_offline_dataloader:', len(val_offline_dataloader.dataset))\n",
    "\n",
    "# d = int(np.log2(config[\"model_params\"][\"num_actions\"]))\n",
    "# val_online_dataloader_1 = get_online_dataloader([Net(d=d, n=2, seed=i) for i in range(271, 281)], config)\n",
    "# val_online_dataloader_2 = get_online_dataloader([Net(d=d, n=2, seed=i) for i in range(1, 11)], config)\n",
    "# print('val_online_dataloader_1:', len(val_online_dataloader_1.dataset))\n",
    "# print('val_online_dataloader_2:', len(val_online_dataloader_2.dataset))\n",
    "\n",
    "# logger = WandbLogger(**config[\"wandb_params\"])\n",
    "# model = DPTSolver(config)\n",
    "\n",
    "# trainer = L.Trainer(\n",
    "#     logger=logger,\n",
    "#     precision=config[\"precision\"],\n",
    "#     max_epochs=config[\"max_epochs\"],\n",
    "#     log_every_n_steps=config[\"log_every_n_steps\"],\n",
    "#     default_root_dir=config[\"wandb_params\"][\"save_dir\"],\n",
    "#     enable_model_summary=False\n",
    "#     # deterministic=True\n",
    "# )\n",
    "# trainer.fit(\n",
    "#     model=model, \n",
    "#     train_dataloaders=train_offline_dataloader, \n",
    "#     val_dataloaders=[val_offline_dataloader,]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_offline_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['target_action'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
