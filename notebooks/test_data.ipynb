{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_path = '../'\n",
    "sys.path.insert(0, root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "\n",
    "# from scripts.create_problem import load_problem_set\n",
    "# from scripts.run_solver import load_results\n",
    "from notebooks.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if a dataset (train, validation or test) contains separable problem classes. It means that if the dataset consists of $n$ different QUBO problem types, for example, Knapsack, MaxCut, etc, the corresponding martixes Q make spatially separable groups in the $\\mathbb{R}^{d \\times d}$ space according to their problem type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = \"../../data/normal\"\n",
    "problem_list = natsorted(os.listdir(read_dir))\n",
    "\n",
    "# problem_list = [\n",
    "#     'SPP',\n",
    "#     'GraphColoring',\n",
    "#     'Knapsack',\n",
    "#     'MVC',\n",
    "#     'QUBO',\n",
    "#     'SetPack',\n",
    "#     'WMaxCut',\n",
    "#     'NumberPartitioning',\n",
    "#     'MaxCut',\n",
    "#     'WMVC',\n",
    "#     'Ising',\n",
    "#     'Max2Sat',\n",
    "#     'QAP'\n",
    "# ]\n",
    "\n",
    "# X, y = get_Xy(read_dir, problem_list, suffix='test')\n",
    "# X_tsne = get_tsne(X)\n",
    "# show_tsne(problem_list, X_tsne, y)\n",
    "# print_unique(read_dir, problem_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimization trajectoriy for every problem from the dataset obtained with different solvers and average them over a problem type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = '../../trajectories/normal'\n",
    "problem_list = natsorted(os.listdir(read_dir))\n",
    "solver_list = ('PSO', 'PROTES', 'GUROBI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first let's collect some statistics for compressed (without dublicates) trajectories from a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_stats = defaultdict(dict)\n",
    "for problem in problem_list:\n",
    "    for solver in solver_list:\n",
    "        meta_stats[problem][solver] = get_trajectory_stats(problem, solver, read_dir, suffix='val')\n",
    "\n",
    "problem_averaged_meta_stats = get_problem_averaged_meta_dict(meta_stats)\n",
    "pd.DataFrame(problem_averaged_meta_stats).T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Than, gather full trajectories from a test dataset and average them to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"../final_results/normal\"\n",
    "meta_results = defaultdict(dict)\n",
    "\n",
    "for problem in problem_list:\n",
    "    for solver in solver_list:\n",
    "        meta_results[problem][solver] = get_meta_results(problem, solver, read_dir, suffix='test')\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, f'solvers.npy')\n",
    "np.save(save_path, meta_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one can go to `utils.py` file and adjust the printing settings. Namely, it is possible to turn off clipping or add information about std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_meta_results(meta_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get one trajectory for a convinient printing average over the problem types as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_meta_results = scale_meta_dict(meta_results)\n",
    "problem_averaged_scaled_meta_results = get_problem_averaged_meta_dict(scaled_meta_results)\n",
    "show_meta_results({'Normal': problem_averaged_scaled_meta_results})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.create_problem import load_problem_set\n",
    "# from scripts.run_solver import load_results\n",
    "\n",
    "# d_x = []\n",
    "# problem_name = 'QAP'\n",
    "# problems = load_problem_set(f'{read_dir}/{problem_name}/train')\n",
    "# for problem in problems:\n",
    "#     d_x.append(problem.info['x_best'])\n",
    "#     print(problem.Q)\n",
    "# x_unique = torch.unique(torch.stack(d_x), dim=0)\n",
    "# print(x_unique)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
