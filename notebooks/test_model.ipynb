{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to test a DPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_path = '../'\n",
    "sys.path.insert(0, root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import numpy as np\n",
    "from natsort import natsorted\n",
    "\n",
    "from train_dpt import DPTSolver\n",
    "from notebooks.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a model from a checkpoint. The last checkpoint is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint(run_name):\n",
    "    root_dir = os.path.join(\"../../results\", \"DPT_3\", run_name, \"checkpoints\")\n",
    "    checkpoint = natsorted(os.listdir(root_dir))[-1]\n",
    "    checkpoint_file = os.path.join(root_dir, checkpoint)\n",
    "    return checkpoint_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "run = \"y9t9d0jr\"\n",
    "checkpoint_file = get_checkpoint(run)\n",
    "model = DPTSolver.load_from_checkpoint(checkpoint_file)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 2 * model.config[\"model_params\"][\"seq_len\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model in an online inference mode for a given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = \"../data/normal\"\n",
    "problem = \"Normal(0, 1)\"\n",
    "logs = run_model(model, read_dir, problem, name=\"AD\", budget=budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one can go to `utils.py` file and adjust the printing settings. Namely, it is possible to move the legend or turn on clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_meta_results({problem: logs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results along with other solvers results to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = \"../results/normal\"\n",
    "problem_list = (problem,) # natsorted(os.listdir(read_dir))\n",
    "solver_list = ('RandomSearch', 'PSO', 'PROTES')\n",
    "\n",
    "meta_results = defaultdict(dict)\n",
    "for problem in problem_list:\n",
    "    for solver in solver_list:\n",
    "        meta_results[problem][solver] = get_meta_results(problem, solver, read_dir, suffix='test', budget=budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_results[problem] |= logs\n",
    "show_meta_results(meta_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup = 0\n",
    "# model.config[\"temperature\"] = lambda x: math.sqrt(x)\n",
    "# model.config[\"temperature\"] = lambda x: 5 - 4 * x\n",
    "# model.config[\"temperature\"] = lambda x: 1 / math.sqrt(1 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in logs.items():\n",
    "#     print(k, len(v[\"m_list\"]), len(v[\"y_list (mean)\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
