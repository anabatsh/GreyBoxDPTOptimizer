{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_path = '../'\n",
    "sys.path.insert(0, root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problems import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.create_problem import load_problem_set\n",
    "import problems as pbs\n",
    "from dpt.data import *\n",
    "from dpt.reward import Reward\n",
    "from train_dpt import *\n",
    "from notebooks.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_state torch.float32 torch.Size([51])\n",
      "target_state torch.float32 torch.Size([51])\n",
      "problem <class 'problems.qubo.Distribution'>\n",
      "states torch.float32 torch.Size([100, 51])\n",
      "actions torch.int64 torch.Size([100, 50])\n",
      "next_states torch.float32 torch.Size([100, 51])\n",
      "target_action torch.int64 torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "problem = 'Normal(0, 1)'\n",
    "data_dir = '../data/normal'\n",
    "results_dir = '../results/normal'\n",
    "suffix = 'test'\n",
    "\n",
    "problems = load_problem_set(os.path.join(data_dir, problem, suffix))\n",
    "dataset = OfflineDataset(problems, seq_len=100, results_dir=results_dir, suffix=suffix, ad_ratio=0.0, action='point', target_action='gt')\n",
    "# dataset = OnlineDataset(problems)\n",
    "sample = dataset[0]\n",
    "\n",
    "for k, v in sample.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(k, v.dtype, v.shape)\n",
    "    else:\n",
    "        print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# target_actions = [torch.argmax(sample['target_action']).item() for _ in range(10) for sample in dataset]\n",
    "# bins = np.arange(0, 12)\n",
    "# plt.hist(target_actions, bins-0.5)\n",
    "# plt.xticks(bins[:-1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model = Reward()\n",
    "rewards = reward_model.offline(sample['states'], sample['actions'], sample['next_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.all(sample['states'][..., :-1].long() ^ sample['actions'][..., :-1] == sample['next_states'][..., :-1].long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpt.loss import RKLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor([[5.8750, 4.7763, 6.2020]])}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 10\n",
    "B = 1\n",
    "S = 3\n",
    "logits = torch.randn((B, S, d + 1))\n",
    "targets = torch.randint(0, 2, (B, d + 1))\n",
    "\n",
    "loss_fn = RKLLoss(label_smoothing=0)\n",
    "loss_fn(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': tensor([[10.3999, 10.3999, 10.3999, 10.3999, 10.3999,  8.5334, 10.3999, 10.3999,\n",
       "          10.3999, 10.3999, 10.3999],\n",
       "         [ 8.4865,  6.7684,  8.4865,  8.4865,  8.4865,  6.7684,  8.4865,  8.4865,\n",
       "           8.4865,  6.7684,  8.4865],\n",
       "         [ 0.0686,  0.0686,  0.0686,  0.0686,  0.0686,  0.0686,  0.0686,  0.0686,\n",
       "           0.0686,  0.0686,  0.0686]])}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.zeros((3, d + 1))\n",
    "targets[0, 5] = 1\n",
    "targets[[1]*3, [1, 5, 9]] = 1\n",
    "targets[2] = 1\n",
    "\n",
    "logits = torch.eye(d + 1).unsqueeze(0).repeat(3, 1, 1)\n",
    "print(logits)\n",
    "print(targets)\n",
    "loss_fn(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1794, -1.6698, -1.3440]]) tensor([[-13.2228, -13.0729, -13.1242]])\n",
      "tensor([[12.0434, 11.4031, 11.7802]])\n"
     ]
    }
   ],
   "source": [
    "d = 5\n",
    "B = 1\n",
    "S = 3\n",
    "logits = torch.randn((B, S, d + 1))\n",
    "targets = torch.randint(0, 2, (B, d + 1))#.unsqueeze(1)#.repeat(1, S, 1)\n",
    "\n",
    "q = F.softmax(logits, dim=-1)\n",
    "p = targets / targets.sum(dim=-1, keepdim=True)\n",
    "\n",
    "loss_qq = (q * torch.log(q + 1e-6)).sum(-1)\n",
    "loss_qp = (q * torch.log(p + 1e-6)).sum(-1)\n",
    "\n",
    "print(loss_qq, loss_qp)\n",
    "loss = (loss_qq - loss_qp)#.mean()\n",
    "print(loss)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "targets\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1]])\n",
      "\n",
      "target indexes\n",
      "tensor([[30, 30, 30,  3,  4,  5,  6,  7, 30, 30, 10]])\n",
      "\n",
      "predictions\n",
      "tensor([[0, 5, 8]])\n",
      "\n",
      "results\n",
      "tensor([[[30, 30, 30,  3,  4,  5,  6,  7, 30, 30, 10],\n",
      "         [25, 25, 25,  2,  1,  0,  1,  2, 25, 25,  5],\n",
      "         [22, 22, 22,  5,  4,  3,  2,  1, 22, 22,  2]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.3333)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "predictions - [batch_size, seq_len + 1, action_dim]\n",
    "targets     - [batch_size, action_dim]\n",
    "\"\"\"\n",
    "\n",
    "d = 10\n",
    "B = 1\n",
    "S = 3\n",
    "predictions = torch.randint(0, d + 1, (B, S))\n",
    "predictions = torch.eye(d + 1)[predictions]\n",
    "targets = torch.randint(0, 2, (B, d + 1)).unsqueeze(1)#.repeat(1, S, 1)\n",
    "\n",
    "accuracy = torch.any(predictions * targets, dim=-1).float().mean()\n",
    "predictions = torch.argmax(predictions, dim=-1)\n",
    "\n",
    "print('\\ntargets')\n",
    "print(targets[:, 0, :])\n",
    "print('\\ntarget indexes')\n",
    "indexes = torch.arange(1, d + 2) * targets - 1\n",
    "indexes[indexes < 0] = 3 * d # imax\n",
    "print(indexes[:, 0, :])\n",
    "print('\\npredictions')\n",
    "print(predictions)\n",
    "print('\\nresults')\n",
    "\n",
    "\n",
    "dists = (indexes - predictions[..., None]).abs()\n",
    "print(dists)\n",
    "mae = dists.min(dim=-1).values.float().mean()\n",
    "mae\n",
    "# targets.where(targets == 1)\n",
    "# mae = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context\n",
      "    00011001011100100111111111111010000011100110110010 8.041    ->  -> 10010011000001010110011110001010001011101011011101 -27.059  -> -2.443\n",
      "    10010011000001010110011110001010001011101011011101 -27.059  ->  -> 00010000010110000010011010100100011111011110111011 -34.388  -> -1.618\n",
      "    00010000010110000010011010100100011111011110111011 -34.388  ->  -> 00111110111100000010110010011111110000000100110111 -21.137  -> -1.578\n",
      "    00111110111100000010110010011111110000000100110111 -21.137  ->  -> 00101110010010101110110001011110110011110101001011 -23.957  -> -2.398\n",
      "    00101110010010101110110001011110110011110101001011 -23.957  ->  -> 00101100101011100101000111001000110010000110001001 1.647    -> -2.876\n",
      "    00101100101011100101000111001000110010000110001001 1.647    ->  -> 10110101111010101001111101100010001101001111111111 -28.611  -> -2.822\n",
      "    10110101111010101001111101100010001101001111111111 -28.611  ->  -> 01000001011101001101001000011011111001111011110011 -19.333  -> -3.478\n",
      "    01000001011101001101001000011011111001111011110011 -19.333  ->  -> 11010101011000110010000111110111100000101011100000 -14.605  -> -3.395\n",
      "    11010101011000110010000111110111100000101011100000 -14.605  ->  -> 00101101001111110001111010011010101100110011010001 -16.430  -> -3.544\n",
      "    00101101001111110001111010011010101100110011010001 -16.430  ->  -> 10011111110010000000101100011100001000010000001110 -86.245  -> -3.194\n",
      "query_state\n",
      "    01010101100001011010110110001110111000011100111110 1.257   \n",
      "target_action\n",
      "    \n",
      "target_state\n",
      "    01011101001100100011101100100001110001011000100010 -169.394\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "print_sample(sample, rewards, 'point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = partial(custom_collate_fn, problem_class=getattr(pbs, 'Problem'))\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=10, collate_fn=collate_fn)\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(k, v.dtype, v.shape)\n",
    "    else:\n",
    "        print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_dpt import ProblemDataModule, DPTSolver, L\n",
    "from notebooks.utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../configs/config.yaml')\n",
    "# config['batch_size'] = 3\n",
    "\n",
    "# config['action'] = \"point\"\n",
    "# # target_action: \"gt\"\n",
    "# # ad_ratio: 0.0\n",
    "# config['model_params']['action_dim'] = 50\n",
    "\n",
    "datamodule = ProblemDataModule(config)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(datamodule.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DPTSolver(config)\n",
    "model.configure_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewards = model.reward_model.offline(\n",
    "rewards = reward_model.offline(\n",
    "    states=batch[\"states\"],\n",
    "    actions=batch[\"actions\"],\n",
    "    next_states=batch[\"next_states\"]\n",
    ")\n",
    "rewards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.model(\n",
    "    query_state=batch[\"query_state\"],\n",
    "    states=batch[\"states\"],\n",
    "    actions=batch[\"actions\"],\n",
    "    next_states=batch[\"next_states\"],\n",
    "    rewards=rewards,\n",
    ")\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    logger=None,\n",
    "    precision=config[\"precision\"] if config[\"strategy\"] != \"fsdp\" else None,\n",
    "    max_epochs=config[\"max_epochs\"],\n",
    "    log_every_n_steps=config[\"log_every_n_steps\"],\n",
    "    default_root_dir=config[\"wandb_params\"][\"save_dir\"],\n",
    "    enable_model_summary=True,\n",
    "    use_distributed_sampler=False,\n",
    "    # strategy=config[\"strategy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
