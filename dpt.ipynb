{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1...\n",
      "OnePlusOne: 100%|███████████████████████████████| 10/10 [00:00<00:00, 17.28it/s]\n",
      "PSO: 100%|██████████████████████████████████████| 10/10 [00:00<00:00, 16.28it/s]\n",
      "NoisyBandit: 100%|██████████████████████████████| 10/10 [00:00<00:00, 18.01it/s]\n",
      "SPSA: 100%|█████████████████████████████████████| 10/10 [00:00<00:00, 17.92it/s]\n",
      "Portfolio: 100%|████████████████████████████████| 10/10 [00:01<00:00,  6.19it/s]\n",
      "Iteration 2...\n",
      "OnePlusOne: 100%|███████████████████████████████| 10/10 [00:00<00:00, 17.31it/s]\n",
      "PSO: 100%|██████████████████████████████████████| 10/10 [00:00<00:00, 15.95it/s]\n",
      "NoisyBandit: 100%|██████████████████████████████| 10/10 [00:00<00:00, 17.99it/s]\n",
      "SPSA: 100%|█████████████████████████████████████| 10/10 [00:00<00:00, 16.94it/s]\n",
      "Portfolio: 100%|████████████████████████████████| 10/10 [00:01<00:00,  6.44it/s]\n",
      "Loading training histories...\n",
      "Num histories: 100\n",
      "Checkpoints path: solvers/dpt/checkpoints\n",
      "Parameters: 12627474\n",
      "Training: 51it [00:00, 53.09it/s]\n"
     ]
    }
   ],
   "source": [
    "!bash dpt_run.sh\n",
    "# the same thing !python3 solvers/dpt/train_dpt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test DPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPT_K2D(\n",
       "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (embed_transition): Linear(in_features=18, out_features=512, bias=True)\n",
       "  (embedd): Linear(in_features=1, out_features=1, bias=True)\n",
       "  (blocks): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (attention): CausalSelfAttentionWithCache(\n",
       "        (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (action_head): Linear(in_features=512, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from solvers.dpt.src.model_dpt import DPT_K2D\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model = DPT_K2D(\n",
    "    num_states=1,\n",
    "    num_actions=16,\n",
    "    hidden_dim=512,\n",
    "    seq_len=50,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    attention_dropout=0.5,\n",
    "    residual_dropout=0.1,\n",
    "    embedding_dropout=0.3,\n",
    "    normalize_qk=False,\n",
    "    pre_norm=True,\n",
    "    rnn_weights_path=None,\n",
    "    state_rnn_embedding=1,\n",
    "    rnn_dropout=0.0,\n",
    ").to(DEVICE)\n",
    "\n",
    "checkpoint_path = \"solvers/dpt/checkpoints/model_last.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | current target: 0.619317 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 1 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 2 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 3 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 4 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 5 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 6 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 7 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 8 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "step 9 | current target: 0.613625 -> suggested point: [0 1 0 1] -> new target: 0.613625\n",
      "\n",
      "found minimal value: 0.613625\n",
      "ground truth: 0.281228\n",
      "\n",
      "all possible targets in an order:\n",
      "[0.28122795 0.2869193  0.3650453  0.3707366  0.39272285 0.3984142\n",
      " 0.41831326 0.42400458 0.47654018 0.4822315  0.50213057 0.5078219\n",
      " 0.52980816 0.53549945 0.61362547 0.6193168 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from utils import int2bin\n",
    "from problems import Net\n",
    "from utils import get_xaxis\n",
    "\n",
    "\n",
    "p = Net(d=4, n=2, seed=100)\n",
    "all_targets = p.target(get_xaxis(d=4, n=2))\n",
    "\n",
    "query_states = torch.tensor([all_targets.max()])\n",
    "context_states = torch.Tensor(1, 0)\n",
    "context_actions = torch.Tensor(1, 0)\n",
    "context_rewards = torch.Tensor(1, 0)\n",
    "\n",
    "for _ in range(10):\n",
    "    predicted_actions = model(\n",
    "        query_states=query_states.to(dtype=torch.float, device=DEVICE),\n",
    "        context_states=context_states.to(dtype=torch.float, device=DEVICE),\n",
    "        context_next_states=None,\n",
    "        context_actions=context_actions.to(dtype=torch.long, device=DEVICE),\n",
    "        context_rewards=context_rewards.to(dtype=torch.float, device=DEVICE),\n",
    "    )    \n",
    "    predicted_action = torch.argmax(F.softmax(predicted_actions, dim=1)).cpu()\n",
    "    point = int2bin(predicted_action, d=4, n=2)\n",
    "    target = torch.tensor(p.target(point))\n",
    "    print(f'step {_} | current target: {query_states.item():>8.6} -> suggested point: {point} -> new target: {target.item():.6}')\n",
    "\n",
    "    context_states = torch.cat([context_states, target.unsqueeze(0)], dim=1)\n",
    "    context_actions = torch.cat([context_actions, torch.tensor([predicted_action]).unsqueeze(0)], dim=1)\n",
    "    context_rewards = torch.cat([context_rewards, (target - query_states).unsqueeze(0)], dim=1)\n",
    "    query_states = target\n",
    "\n",
    "print()\n",
    "print(f'found minimal value: {target.item():.6}')\n",
    "print(f'ground truth: {all_targets.min().item():.6}')\n",
    "print()\n",
    "print(f'all possible targets in an order:\\n{np.sort(all_targets)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset = MarkovianDataset(\"trajectories/\", seq_len=200)\n",
    "# # dataloader = DataLoader(dataset=dataset, batch_size=1, pin_memory=True, shuffle=False, num_workers=0)\n",
    "\n",
    "# for batch in dataloader:\n",
    "#     (\n",
    "#         query_flag,\n",
    "#         query_states,\n",
    "#         flags,\n",
    "#         states,\n",
    "#         actions,\n",
    "#         next_flags,\n",
    "#         next_states,\n",
    "#         rewards,\n",
    "#         target_actions,\n",
    "#     ) = [b.to(dtype=torch.float, device=DEVICE) for b in batch]\n",
    "#     break\n",
    "\n",
    "# actions = actions.to(torch.long)\n",
    "\n",
    "# predicted_actions = model(\n",
    "#     query_states=query_states,\n",
    "#     context_states=states,\n",
    "#     context_next_states=next_states,\n",
    "#     context_actions=actions,\n",
    "#     context_rewards=rewards,\n",
    "# )\n",
    "\n",
    "# predicted_action = torch.argmax(F.softmax(predicted_actions, dim=1))\n",
    "# target_actions, predicted_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from solvers.dpt.src.utils.data import MarkovianDataset\n",
    "from solvers.dpt.src.model_dpt import DPT_K2D\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "dataset = MarkovianDataset('trajectories', seq_len=200)\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=128,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DPT_K2D(\n",
    "    num_states=1,\n",
    "    num_actions=10,\n",
    "    hidden_dim=512,\n",
    "    seq_len=200,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    attention_dropout=0.5,\n",
    "    residual_dropout=0.1,\n",
    "    embedding_dropout=0.3,\n",
    "    normalize_qk=False,\n",
    "    pre_norm=True,\n",
    "    rnn_weights_path=None,\n",
    "    state_rnn_embedding=16,\n",
    "    rnn_dropout=0.0,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    (\n",
    "        query_flag,\n",
    "        query_states,\n",
    "        flags,\n",
    "        states,\n",
    "        actions,\n",
    "        next_flags,\n",
    "        next_states,\n",
    "        rewards,\n",
    "        target_actions,\n",
    "    ) = [b.to(DEVICE) for b in batch]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_states = query_states.to(torch.float)\n",
    "states = states.to(torch.float)\n",
    "actions = actions.to(torch.long)\n",
    "next_states = next_states.to(torch.float)\n",
    "rewards = rewards.to(torch.float32)\n",
    "\n",
    "target_actions = target_actions.squeeze(-1)\n",
    "target_actions = (\n",
    "    F.one_hot(target_actions, num_classes=10)\n",
    "    .unsqueeze(1)\n",
    "    .repeat(1, 200, 1)\n",
    "    .float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_actions = model(\n",
    "    query_states=query_states,\n",
    "    context_states=states,\n",
    "    context_next_states=next_states,\n",
    "    context_actions=actions,\n",
    "    context_rewards=rewards,\n",
    ")\n",
    "predicted_actions = predicted_actions[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.cross_entropy(\n",
    "    input=predicted_actions.flatten(0, 1),\n",
    "    target=target_actions.flatten(0, 1),\n",
    "    label_smoothing=0.0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
